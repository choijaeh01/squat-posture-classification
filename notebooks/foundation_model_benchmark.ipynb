{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스쿼트 파운데이션 모델 벤치마크 노트북\n",
    "\n",
    "이 노트북은 라벨링된 스쿼트 데이터셋으로 CNN, CNN-GRU, ViT 기반 모델을 학습·평가해 성능을 비교하기 위한 베이스라인 워크플로를 제공합니다. 아래 순서를 따라가면서 데이터를 불러오고, 증강을 적용하고, 각 모델을 학습/검증/테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 공통 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 프로젝트 소스 경로를 PYTHONPATH에 추가\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.augmentations import (\n",
    "    add_gaussian_noise,\n",
    "    compose_transforms,\n",
    "    random_time_shift,\n",
    "    random_time_stretch,\n",
    "    random_time_warp,\n",
    "    random_scaling,\n",
    ")\n",
    "from src.data_loading import (\n",
    "    DatasetLayout,\n",
    "    SquatWindowDataset,\n",
    "    iter_class_counts,\n",
    "    make_dataloader,\n",
    "    train_val_test_split,\n",
    ")\n",
    "from src.models import TemporalCNNGRU\n",
    "\n",
    "torch.manual_seed(41)\n",
    "np.random.seed(41)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 구성 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 결과 저장 경로 설정\n",
    "DATA_ROOT = (PROJECT_ROOT / \"data\").resolve()\n",
    "RESULTS_DIR = (PROJECT_ROOT / \"results\" / \"foundation_models\").resolve()\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "layout = DatasetLayout(DATA_ROOT)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강 파이프라인 정의 및 원본 데이터 로드\n",
    "train_transforms = compose_transforms(\n",
    "    [\n",
    "        random_time_shift(max_shift=5),\n",
    "        random_scaling(0.9, 1.1),\n",
    "        random_time_stretch(0.85, 1.2),\n",
    "        random_time_warp(0.15),\n",
    "        add_gaussian_noise(0.01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "raw_dataset = SquatWindowDataset(layout.manually_labeled, transforms=None)\n",
    "len(raw_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스별 샘플 분포 확인\n",
    "counts = list(iter_class_counts(raw_dataset))\n",
    "pd.DataFrame([(cls.name, count) for cls, count in counts], columns=[\"class\", \"count\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증/테스트 분할 및 데이터로더 생성\n",
    "train_subset, val_subset, test_subset = train_val_test_split(raw_dataset, ratios=(0.7, 0.15, 0.15), seed=41)\n",
    "\n",
    "class AugmentedSubset(Dataset):\n",
    "    def __init__(self, subset: Subset, transform: Optional[Callable[[torch.Tensor], torch.Tensor]] = None) -> None:\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        window, label = self.subset[index]\n",
    "        if self.transform is not None:\n",
    "            window = self.transform(window)\n",
    "        return window, label\n",
    "\n",
    "train_dataset = AugmentedSubset(train_subset, transform=train_transforms)\n",
    "val_dataset = AugmentedSubset(val_subset)\n",
    "test_dataset = AugmentedSubset(test_subset)\n",
    "\n",
    "train_loader = make_dataloader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = make_dataloader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = make_dataloader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "next(iter(train_loader))[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 공통 학습 루틴 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 30\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-3\n",
    "    grad_clip: float = 5.0\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    config: \"TrainingConfig\",\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss, total_samples = 0.0, 0\n",
    "\n",
    "    for batch, targets in tqdm(loader, desc=\"train\", leave=False):\n",
    "        batch, targets = batch.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)\n",
    "        loss = criterion(logits, targets)\n",
    "        loss.backward()\n",
    "        if config.grad_clip:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch.size(0)\n",
    "        total_samples += batch.size(0)\n",
    "\n",
    "    return total_loss / max(total_samples, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion: nn.Module) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "\n",
    "    for batch, targets in tqdm(loader, desc=\"eval\", leave=False):\n",
    "        batch, targets = batch.to(DEVICE), targets.to(DEVICE)\n",
    "        logits = model(batch)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        total_loss += loss.item() * batch.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == targets).sum().item()\n",
    "        total_samples += batch.size(0)\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / max(total_samples, 1),\n",
    "        \"accuracy\": total_correct / max(total_samples, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    config: \"TrainingConfig\",\n",
    ") -> Tuple[nn.Module, Dict[str, List[float]]]:\n",
    "    model = model.to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_score = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, config)\n",
    "        metrics = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(metrics[\"loss\"])\n",
    "        history[\"val_acc\"].append(metrics[\"accuracy\"])\n",
    "\n",
    "        if metrics[\"accuracy\"] > best_score:\n",
    "            best_score = metrics[\"accuracy\"]\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | val_loss={metrics['loss']:.4f} | val_acc={metrics['accuracy']:.3%}\"\n",
    "        )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "config = TrainingConfig(epochs=30, learning_rate=3e-4, weight_decay=1e-3, grad_clip=5.0)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 정의\n",
    "\n",
    "기본 CNN, CNN-GRU(TemporalCNNGRU), IMU 전용 ViT를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBaseline(nn.Module):\n",
    "    \"\"\"간단한 1D CNN 분류기.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ViTSensor(nn.Module):\n",
    "    \"\"\"간단한 시계열 Vision Transformer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        seq_len: int,\n",
    "        patch_size: int = 16,\n",
    "        dim: int = 128,\n",
    "        depth: int = 4,\n",
    "        heads: int = 4,\n",
    "        mlp_ratio: float = 2.0,\n",
    "        dropout: float = 0.1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert seq_len % patch_size == 0, \"Sequence length must be divisible by patch size.\"\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = seq_len // patch_size\n",
    "        self.patch_dim = in_channels * patch_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Unfold(kernel_size=(1, patch_size), stride=(1, patch_size)),\n",
    "        )\n",
    "        self.linear_proj = nn.Linear(self.patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=int(dim * mlp_ratio),\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, c, t = x.shape\n",
    "        x = x.unsqueeze(2)  # (b, c, 1, t)\n",
    "        patches = self.to_patch_embedding(x)  # (b, c * patch_size, num_patches)\n",
    "        patches = patches.transpose(1, 2)  # (b, num_patches, patch_dim)\n",
    "        tokens = self.linear_proj(patches)\n",
    "\n",
    "        cls_tokens = self.cls_token.repeat(b, 1, 1)\n",
    "        tokens = torch.cat([cls_tokens, tokens], dim=1)\n",
    "        tokens = tokens + self.pos_embedding[:, : tokens.size(1), :]\n",
    "\n",
    "        encoded = self.transformer(tokens)\n",
    "        return self.mlp_head(encoded[:, 0])\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \"\"\"CNN feature extractor followed by an LSTM head.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_channels: int = 64,\n",
    "        hidden_size: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, conv_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(conv_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(conv_channels, conv_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(conv_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=conv_channels,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size * 2),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.encoder(x)\n",
    "        sequence = features.transpose(1, 2)\n",
    "        output, _ = self.lstm(sequence)\n",
    "        pooled = output.mean(dim=1)\n",
    "        return self.head(pooled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 및 검증\n",
    "\n",
    "모델별로 학습을 수행하고, 검증 성능을 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_input_shape(loader: DataLoader) -> Tuple[int, int]:\n",
    "    sample, _ = next(iter(loader))\n",
    "    return sample.size(1), sample.size(2)\n",
    "\n",
    "\n",
    "in_channels, seq_len = infer_input_shape(train_loader)\n",
    "num_classes = 5\n",
    "\n",
    "model_factories: Dict[str, Callable[[], nn.Module]] = {\n",
    "    \"CNNBaseline\": lambda: CNNBaseline(in_channels, num_classes),\n",
    "    \"CNNLSTM\": lambda: CNNLSTM(in_channels, num_classes),\n",
    "    \"TemporalCNNGRU\": lambda: TemporalCNNGRU(in_channels=in_channels, num_classes=num_classes),\n",
    "    \"ViTSensor\": lambda: ViTSensor(in_channels=in_channels, num_classes=num_classes, seq_len=seq_len, patch_size=16),\n",
    "}\n",
    "\n",
    "histories: Dict[str, Dict[str, List[float]]] = {}\n",
    "val_metrics: Dict[str, Dict[str, float]] = {}\n",
    "trained_models: Dict[str, nn.Module] = {}\n",
    "\n",
    "for name, factory in model_factories.items():\n",
    "    print(f\"\\n=== Training: {name} ===\")\n",
    "    model = factory()\n",
    "    model, history = fit(model, train_loader, val_loader, config)\n",
    "    metrics = evaluate(model, val_loader, nn.CrossEntropyLoss())\n",
    "\n",
    "    histories[name] = history\n",
    "    val_metrics[name] = metrics\n",
    "    trained_models[name] = model\n",
    "\n",
    "pd.DataFrame(val_metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 테스트 세트 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    metrics = evaluate(model, test_loader, criterion)\n",
    "    test_results[name] = metrics\n",
    "    print(f\"{name} | test_loss={metrics['loss']:.4f} | test_acc={metrics['accuracy']:.3%}\")\n",
    "\n",
    "test_df = pd.DataFrame(test_results).T\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 결과 저장 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"val_metrics\": val_metrics,\n",
    "    \"test_metrics\": test_results,\n",
    "    \"config\": config.__dict__,\n",
    "}\n",
    "\n",
    "summary_path = RESULTS_DIR / \"foundation_model_results.json\"\n",
    "with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "summary_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요에 따라 `histories`를 활용해 학습 곡선을 시각화하거나, 혼동 행렬과 같은 추가 분석을 이어가세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}